---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: mon
    app.kubernetes.io/name: ceph
    app.kubernetes.io/part-of: kubernetes
  name: ceph-mon-a
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: mon
      app.kubernetes.io/name: ceph
      app.kubernetes.io/part-of: kubernetes
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 100%
  template:
    metadata:
      labels:
        app.kubernetes.io/component: mon
        app.kubernetes.io/name: ceph
        app.kubernetes.io/part-of: kubernetes
        ceph.kubernetes.progamesigner.dev/mon: a
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: mon.ceph.kubernetes.progamesigner.dev/a
                operator: Exists
      automountServiceAccountToken: true
      initContainers:
      - name: chown
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          cp -LRv /mnt/ceph/*.keyring /etc/ceph/;
          cp -LRv /mnt/ceph-conf/ceph.conf /etc/ceph/ceph.conf;

          mkdir -p /var/lib/ceph/mon/ceph-${CEPH_NAME};

          chown -R 167:167 /etc/ceph;
          chown -R 167:167 /var/lib/ceph/mon/ceph-${CEPH_NAME};
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mon']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /mnt/ceph
          readOnly: true
        - name: ceph-conf
          mountPath: /mnt/ceph-conf
          readOnly: true
        - name: conf
          mountPath: /etc/ceph
        - name: data
          mountPath: /var/lib/ceph
      - name: setup
        image: ceph/ceph:latest
        command:
        - ceph-mon
        args:
        - --id=$(CEPH_NAME)
        - --keyring=/etc/ceph/ceph.mon.keyring
        - --mkfs
        - --setgroup=ceph
        - --setuser=ceph
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mon']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      containers:
      - name: mon
        image: ceph/ceph:latest
        command:
        - ceph-mon
        args:
        - --foreground
        - --id=$(CEPH_NAME)
        - --public-bind-addr=$(POD_IP)
        - --setgroup=ceph
        - --setuser=ceph
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mon']
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        ports:
        - name: ceph-mon
          containerPort: 3300
          protocol: TCP
        - name: ceph-mon-v1
          containerPort: 6789
          protocol: TCP
        startupProbe:
          exec:
            command:
            - sh
            - -c
            - |
              output="$(ceph --admin-daemon /run/ceph/ceph-mon.${CEPH_NAME}.asok mon_status 2>&1)"
              rc=$?
              if [ $rc -ne 0 ]; then
                echo "ceph daemon health check failed with the following output:"
                echo "$output" | sed -e 's/^/> /g'
                exit $rc
              fi
          initialDelaySeconds: 15
          periodSeconds: 60
          timeoutSeconds: 30
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - |
              output="$(ceph --admin-daemon /run/ceph/ceph-mon.${CEPH_NAME}.asok mon_status 2>&1)"
              rc=$?
              if [ $rc -ne 0 ]; then
                echo "ceph daemon health check failed with the following output:"
                echo "$output" | sed -e 's/^/> /g'
                exit $rc
              fi
          initialDelaySeconds: 15
          periodSeconds: 60
          timeoutSeconds: 30
        resources:
          limits:
            cpu: 300m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 32Mi
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      priorityClassName: system-cluster-critical
      serviceAccountName: ceph
      volumes:
      - name: ceph
        hostPath:
          path: /etc/ceph
      - name: ceph-conf
        configMap:
          name: ceph
          items:
          - key: ceph.conf
            path: ceph.conf
      - name: conf
        emptyDir: {}
      - name: data
        hostPath:
          path: /var/lib/ceph
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: mon
    app.kubernetes.io/name: ceph
    app.kubernetes.io/part-of: kubernetes
  name: ceph-mon-b
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: mon
      app.kubernetes.io/name: ceph
      app.kubernetes.io/part-of: kubernetes
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 100%
  template:
    metadata:
      labels:
        app.kubernetes.io/component: mon
        app.kubernetes.io/name: ceph
        app.kubernetes.io/part-of: kubernetes
        ceph.kubernetes.progamesigner.dev/mon: b
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: mon.ceph.kubernetes.progamesigner.dev/b
                operator: Exists
      automountServiceAccountToken: true
      initContainers:
      - name: chown
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          cp -LRv /mnt/ceph/*.keyring /etc/ceph/;
          cp -LRv /mnt/ceph-conf/ceph.conf /etc/ceph/ceph.conf;

          mkdir -p /var/lib/ceph/mon/ceph-${CEPH_NAME};

          chown -R 167:167 /etc/ceph;
          chown -R 167:167 /var/lib/ceph/mon/ceph-${CEPH_NAME};
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mon']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /mnt/ceph
          readOnly: true
        - name: ceph-conf
          mountPath: /mnt/ceph-conf
          readOnly: true
        - name: conf
          mountPath: /etc/ceph
      - name: setup
        image: ceph/ceph:latest
        command:
        - ceph-mon
        args:
        - --id=$(CEPH_NAME)
        - --keyring=/etc/ceph/ceph.mon.keyring
        - --mkfs
        - --setgroup=ceph
        - --setuser=ceph
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mon']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      containers:
      - name: mon
        image: ceph/ceph:latest
        command:
        - ceph-mon
        args:
        - --foreground
        - --id=$(CEPH_NAME)
        - --public-bind-addr=$(POD_IP)
        - --setgroup=ceph
        - --setuser=ceph
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mon']
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        ports:
        - name: ceph-mon
          containerPort: 3300
          protocol: TCP
        - name: ceph-mon-v1
          containerPort: 6789
          protocol: TCP
        startupProbe:
          exec:
            command:
            - sh
            - -c
            - |
              output="$(ceph --admin-daemon /run/ceph/ceph-mon.${CEPH_NAME}.asok mon_status 2>&1)"
              rc=$?
              if [ $rc -ne 0 ]; then
                echo "ceph daemon health check failed with the following output:"
                echo "$output" | sed -e 's/^/> /g'
                exit $rc
              fi
          initialDelaySeconds: 15
          periodSeconds: 60
          timeoutSeconds: 30
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - |
              output="$(ceph --admin-daemon /run/ceph/ceph-mon.${CEPH_NAME}.asok mon_status 2>&1)"
              rc=$?
              if [ $rc -ne 0 ]; then
                echo "ceph daemon health check failed with the following output:"
                echo "$output" | sed -e 's/^/> /g'
                exit $rc
              fi
          initialDelaySeconds: 15
          periodSeconds: 60
          timeoutSeconds: 30
        resources:
          limits:
            cpu: 300m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 32Mi
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      priorityClassName: system-cluster-critical
      serviceAccountName: ceph
      volumes:
      - name: ceph
        hostPath:
          path: /etc/ceph
      - name: ceph-conf
        configMap:
          name: ceph
          items:
          - key: ceph.conf
            path: ceph.conf
      - name: conf
        emptyDir: {}
      - name: data
        hostPath:
          path: /var/lib/ceph
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: mon
    app.kubernetes.io/name: ceph
    app.kubernetes.io/part-of: kubernetes
  name: ceph-mon-c
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: mon
      app.kubernetes.io/name: ceph
      app.kubernetes.io/part-of: kubernetes
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 100%
  template:
    metadata:
      labels:
        app.kubernetes.io/component: mon
        app.kubernetes.io/name: ceph
        app.kubernetes.io/part-of: kubernetes
        ceph.kubernetes.progamesigner.dev/mon: c
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: mon.ceph.kubernetes.progamesigner.dev/c
                operator: Exists
      automountServiceAccountToken: true
      initContainers:
      - name: chown
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          cp -LRv /mnt/ceph/*.keyring /etc/ceph/;
          cp -LRv /mnt/ceph-conf/ceph.conf /etc/ceph/ceph.conf;

          mkdir -p /var/lib/ceph/mon/ceph-${CEPH_NAME};

          chown -R 167:167 /etc/ceph;
          chown -R 167:167 /var/lib/ceph/mon/ceph-${CEPH_NAME};
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mon']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /mnt/ceph
          readOnly: true
        - name: ceph-conf
          mountPath: /mnt/ceph-conf
          readOnly: true
        - name: conf
          mountPath: /etc/ceph
      - name: setup
        image: ceph/ceph:latest
        command:
        - ceph-mon
        args:
        - --id=$(CEPH_NAME)
        - --keyring=/etc/ceph/ceph.mon.keyring
        - --mkfs
        - --setgroup=ceph
        - --setuser=ceph
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mon']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      containers:
      - name: mon
        image: ceph/ceph:latest
        command:
        - ceph-mon
        args:
        - --foreground
        - --id=$(CEPH_NAME)
        - --public-bind-addr=$(POD_IP)
        - --setgroup=ceph
        - --setuser=ceph
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mon']
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        ports:
        - name: ceph-mon
          containerPort: 3300
          protocol: TCP
        - name: ceph-mon-v1
          containerPort: 6789
          protocol: TCP
        startupProbe:
          exec:
            command:
            - sh
            - -c
            - |
              output="$(ceph --admin-daemon /run/ceph/ceph-mon.${CEPH_NAME}.asok mon_status 2>&1)"
              rc=$?
              if [ $rc -ne 0 ]; then
                echo "ceph daemon health check failed with the following output:"
                echo "$output" | sed -e 's/^/> /g'
                exit $rc
              fi
          initialDelaySeconds: 15
          periodSeconds: 60
          timeoutSeconds: 30
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - |
              output="$(ceph --admin-daemon /run/ceph/ceph-mon.${CEPH_NAME}.asok mon_status 2>&1)"
              rc=$?
              if [ $rc -ne 0 ]; then
                echo "ceph daemon health check failed with the following output:"
                echo "$output" | sed -e 's/^/> /g'
                exit $rc
              fi
          initialDelaySeconds: 15
          periodSeconds: 60
          timeoutSeconds: 30
        resources:
          limits:
            cpu: 300m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 32Mi
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      priorityClassName: system-cluster-critical
      serviceAccountName: ceph
      volumes:
      - name: ceph
        hostPath:
          path: /etc/ceph
      - name: ceph-conf
        configMap:
          name: ceph
          items:
          - key: ceph.conf
            path: ceph.conf
      - name: conf
        emptyDir: {}
      - name: data
        hostPath:
          path: /var/lib/ceph
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: mgr
    app.kubernetes.io/name: ceph
    app.kubernetes.io/part-of: kubernetes
  name: ceph-mgr-a
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: mgr
      app.kubernetes.io/name: ceph
      app.kubernetes.io/part-of: kubernetes
  template:
    metadata:
      labels:
        app.kubernetes.io/component: mgr
        app.kubernetes.io/name: ceph
        app.kubernetes.io/part-of: kubernetes
        ceph.kubernetes.progamesigner.dev/mgr: a
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: mgr.ceph.kubernetes.progamesigner.dev/a
                operator: Exists
      automountServiceAccountToken: true
      initContainers:
      - name: chown
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          cp -LRv /mnt/ceph/*.keyring /etc/ceph/;
          cp -LRv /mnt/ceph-conf/ceph.conf /etc/ceph/ceph.conf;

          mkdir -p /var/lib/ceph/mgr/ceph-${CEPH_NAME};

          chown -R 167:167 /etc/ceph;
          chown -R 167:167 /var/lib/ceph/mgr/ceph-${CEPH_NAME};
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mgr']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /mnt/ceph
          readOnly: true
        - name: ceph-conf
          mountPath: /mnt/ceph-conf
          readOnly: true
        - name: conf
          mountPath: /etc/ceph
        - name: data
          mountPath: /var/lib/ceph
      - name: setup
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          while ! ceph mon dump; do
            echo "Waiting for mon to be ready ...";
            sleep 5;
          done

          if [ ! -f /var/lib/ceph/mgr/ceph-${CEPH_NAME}/keyring ]; then
            ceph auth add mgr.$(CEPH_NAME) mon 'allow profile mgr' osd 'allow *' mds 'allow *';
            ceph auth get mgr.$(CEPH_NAME) > /var/lib/ceph/mgr/ceph-${CEPH_NAME}/keyring;
          fi
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mgr']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      containers:
      - name: mgr
        image: ceph/ceph:latest
        command:
        - ceph-mgr
        args:
        - --foreground
        - --id=$(CEPH_NAME)
        - --setgroup=ceph
        - --setuser=ceph
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mgr']
        ports:
        - name: https
          containerPort: 8443
          protocol: TCP
        resources:
          limits:
            cpu: 300m
            memory: 2Gi
          requests:
            cpu: 100m
            memory: 256Mi
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      priorityClassName: system-cluster-critical
      serviceAccountName: ceph
      volumes:
      - name: ceph
        hostPath:
          path: /etc/ceph
      - name: ceph-conf
        configMap:
          name: ceph
          items:
          - key: ceph.conf
            path: ceph.conf
      - name: conf
        emptyDir: {}
      - name: data
        hostPath:
          path: /var/lib/ceph
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: mgr
    app.kubernetes.io/name: ceph
    app.kubernetes.io/part-of: kubernetes
  name: ceph-mgr-b
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: mgr
      app.kubernetes.io/name: ceph
      app.kubernetes.io/part-of: kubernetes
  template:
    metadata:
      labels:
        app.kubernetes.io/component: mgr
        app.kubernetes.io/name: ceph
        app.kubernetes.io/part-of: kubernetes
        ceph.kubernetes.progamesigner.dev/mgr: b
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: mgr.ceph.kubernetes.progamesigner.dev/b
                operator: Exists
      automountServiceAccountToken: true
      initContainers:
      - name: chown
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          cp -LRv /mnt/ceph/*.keyring /etc/ceph/;
          cp -LRv /mnt/ceph-conf/ceph.conf /etc/ceph/ceph.conf;

          mkdir -p /var/lib/ceph/mgr/ceph-${CEPH_NAME};

          chown -R 167:167 /etc/ceph;
          chown -R 167:167 /var/lib/ceph/mgr/ceph-${CEPH_NAME};
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mgr']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /mnt/ceph
          readOnly: true
        - name: ceph-conf
          mountPath: /mnt/ceph-conf
          readOnly: true
        - name: conf
          mountPath: /etc/ceph
        - name: data
          mountPath: /var/lib/ceph
      - name: setup
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          while ! ceph mon dump; do
            echo "Waiting for mon to be ready ...";
            sleep 5;
          done

          if [ ! -f /var/lib/ceph/mgr/ceph-${CEPH_NAME}/keyring ]; then
            ceph auth add mgr.$(CEPH_NAME) mon 'allow profile mgr' osd 'allow *' mds 'allow *';
            ceph auth get mgr.$(CEPH_NAME) > /var/lib/ceph/mgr/ceph-${CEPH_NAME}/keyring;
          fi
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mgr']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      containers:
      - name: mgr
        image: ceph/ceph:latest
        command:
        - ceph-mgr
        args:
        - --foreground
        - --id=$(CEPH_NAME)
        - --setgroup=ceph
        - --setuser=ceph
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/mgr']
        ports:
        - name: http
          containerPort: 8443
          protocol: TCP
        resources:
          limits:
            cpu: 300m
            memory: 2Gi
          requests:
            cpu: 100m
            memory: 256Mi
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
      priorityClassName: system-cluster-critical
      serviceAccountName: ceph
      volumes:
      - name: ceph
        hostPath:
          path: /etc/ceph
      - name: ceph-conf
        configMap:
          name: ceph
          items:
          - key: ceph.conf
            path: ceph.conf
      - name: conf
        emptyDir: {}
      - name: data
        hostPath:
          path: /var/lib/ceph
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: osd
    app.kubernetes.io/name: ceph
    app.kubernetes.io/part-of: kubernetes
  name: ceph-osd-24
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: osd
      app.kubernetes.io/name: ceph
      app.kubernetes.io/part-of: kubernetes
  template:
    metadata:
      annotations:
        ceph.kubernetes.progamesigner.dev/osd-lvm-lg: ceph-osd24-lv
        ceph.kubernetes.progamesigner.dev/osd-lvm-vg: ceph-vg
      labels:
        app.kubernetes.io/component: osd
        app.kubernetes.io/name: ceph
        app.kubernetes.io/part-of: kubernetes
        ceph.kubernetes.progamesigner.dev/osd: '27'
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: osd.ceph.kubernetes.progamesigner.dev/24
                operator: Exists
      automountServiceAccountToken: true
      hostIPC: true
      initContainers:
      - name: chown
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          cp -LRv /mnt/ceph/*.keyring /etc/ceph/;
          cp -LRv /mnt/ceph-conf/ceph.conf /etc/ceph/ceph.conf;

          mkdir -p /var/lib/ceph/osd/ceph-${CEPH_NAME};

          chown -R 167:167 /etc/ceph;
          chown -R 167:167 /var/lib/ceph/osd/ceph-${CEPH_NAME};
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /mnt/ceph
          readOnly: true
        - name: ceph-conf
          mountPath: /mnt/ceph-conf
          readOnly: true
        - name: conf
          mountPath: /etc/ceph
        - name: data
          mountPath: /var/lib/ceph
      - name: setup
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          while ! ceph mon dump; do
            echo "Waiting for mon to be ready ...";
            sleep 5;
          done

          if [ ! -f /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid ]; then
            ceph-volume lvm prepare --data ${CEPH_LVM_VG}/${CEPH_LVM_LG} --dmcrypt --osd-id ${CEPH_NAME} --no-systemd;
            sleep 5;
            echo $(ceph-volume lvm list --format json | jq -r --arg osd "${CEPH_NAME}" 'getpath([$osd,0,"tags","ceph.osd_fsid"])') > /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid;
          fi
        env:
        - name: CEPH_LVM_LG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['ceph.kubernetes.progamesigner.dev/osd-lvm-lg']
        - name: CEPH_LVM_VG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['ceph.kubernetes.progamesigner.dev/osd-lvm-vg']
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
        securityContext:
          privileged: true
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
        - name: dev
          mountPath: /dev
        - name: run-ceph
          mountPath: /run/ceph
        - name: run-lvm
          mountPath: /run/lvm
        - name: run-udev
          mountPath: /run/udev
      containers:
      - name: osd
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          CEPH_FSID=$(cat /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid);

          ceph-volume lvm activate ${CEPH_NAME} ${CEPH_FSID} --no-systemd;

          exec ceph-osd --foreground --id=${CEPH_NAME} --setgroup=ceph --setuser=ceph;
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          limits:
            cpu: 300m
            memory: 16Gi
          requests:
            cpu: 100m
            memory: 2Gi
        securityContext:
          privileged: true
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
        - name: dev
          mountPath: /dev
        - name: run-lvm
          mountPath: /run/lvm
      priorityClassName: system-cluster-critical
      serviceAccountName: ceph
      volumes:
      - name: ceph
        hostPath:
          path: /etc/ceph
      - name: ceph-conf
        configMap:
          name: ceph
          items:
          - key: ceph.conf
            path: ceph.conf
      - name: conf
        emptyDir: {}
      - name: data
        hostPath:
          path: /var/lib/ceph
      - name: dev
        hostPath:
          path: /dev
      - name: run-ceph
        emptyDir: {}
      - name: run-lvm
        hostPath:
          path: /run/lvm
      - name: run-udev
        hostPath:
          path: /run/udev
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: osd
    app.kubernetes.io/name: ceph
    app.kubernetes.io/part-of: kubernetes
  name: ceph-osd-24a
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: osd
      app.kubernetes.io/name: ceph
      app.kubernetes.io/part-of: kubernetes
  template:
    metadata:
      annotations:
        ceph.kubernetes.progamesigner.dev/osd-lvm-lg: ceph-osd24a-lv
        ceph.kubernetes.progamesigner.dev/osd-lvm-vg: ceph-vg
      labels:
        app.kubernetes.io/component: osd
        app.kubernetes.io/name: ceph
        app.kubernetes.io/part-of: kubernetes
        ceph.kubernetes.progamesigner.dev/osd: '26'
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: osd.ceph.kubernetes.progamesigner.dev/24a
                operator: Exists
      automountServiceAccountToken: true
      hostIPC: true
      initContainers:
      - name: chown
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          cp -LRv /mnt/ceph/*.keyring /etc/ceph/;
          cp -LRv /mnt/ceph-conf/ceph.conf /etc/ceph/ceph.conf;

          mkdir -p /var/lib/ceph/osd/ceph-${CEPH_NAME};

          chown -R 167:167 /etc/ceph;
          chown -R 167:167 /var/lib/ceph/osd/ceph-${CEPH_NAME};
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /mnt/ceph
          readOnly: true
        - name: ceph-conf
          mountPath: /mnt/ceph-conf
          readOnly: true
        - name: conf
          mountPath: /etc/ceph
        - name: data
          mountPath: /var/lib/ceph
      - name: setup
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          while ! ceph mon dump; do
            echo "Waiting for mon to be ready ...";
            sleep 5;
          done

          if [ ! -f /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid ]; then
            ceph-volume lvm prepare --data ${CEPH_LVM_VG}/${CEPH_LVM_LG} --dmcrypt --osd-id ${CEPH_NAME} --no-systemd;
            sleep 5;
            echo $(ceph-volume lvm list --format json | jq -r --arg osd "${CEPH_NAME}" 'getpath([$osd,0,"tags","ceph.osd_fsid"])') > /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid;
          fi
        env:
        - name: CEPH_LVM_LG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['ceph.kubernetes.progamesigner.dev/osd-lvm-lg']
        - name: CEPH_LVM_VG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['ceph.kubernetes.progamesigner.dev/osd-lvm-vg']
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
        securityContext:
          privileged: true
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
        - name: dev
          mountPath: /dev
        - name: run-ceph
          mountPath: /run/ceph
        - name: run-lvm
          mountPath: /run/lvm
        - name: run-udev
          mountPath: /run/udev
      containers:
      - name: osd
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          CEPH_FSID=$(cat /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid);

          ceph-volume lvm activate ${CEPH_NAME} ${CEPH_FSID} --no-systemd;

          exec ceph-osd --foreground --id=${CEPH_NAME} --setgroup=ceph --setuser=ceph;
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          limits:
            cpu: 300m
            memory: 8Gi
          requests:
            cpu: 100m
            memory: 2Gi
        securityContext:
          privileged: true
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
        - name: dev
          mountPath: /dev
        - name: run-lvm
          mountPath: /run/lvm
      priorityClassName: system-cluster-critical
      serviceAccountName: ceph
      volumes:
      - name: ceph
        hostPath:
          path: /etc/ceph
      - name: ceph-conf
        configMap:
          name: ceph
          items:
          - key: ceph.conf
            path: ceph.conf
      - name: conf
        emptyDir: {}
      - name: data
        hostPath:
          path: /var/lib/ceph
      - name: dev
        hostPath:
          path: /dev
      - name: run-ceph
        emptyDir: {}
      - name: run-lvm
        hostPath:
          path: /run/lvm
      - name: run-udev
        hostPath:
          path: /run/udev
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: osd
    app.kubernetes.io/name: ceph
    app.kubernetes.io/part-of: kubernetes
  name: ceph-osd-27
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: osd
      app.kubernetes.io/name: ceph
      app.kubernetes.io/part-of: kubernetes
  template:
    metadata:
      annotations:
        ceph.kubernetes.progamesigner.dev/osd-lvm-lg: ceph-osd27-lv
        ceph.kubernetes.progamesigner.dev/osd-lvm-vg: ceph-vg
      labels:
        app.kubernetes.io/component: osd
        app.kubernetes.io/name: ceph
        app.kubernetes.io/part-of: kubernetes
        ceph.kubernetes.progamesigner.dev/osd: '30'
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: osd.ceph.kubernetes.progamesigner.dev/27
                operator: Exists
      automountServiceAccountToken: true
      hostIPC: true
      initContainers:
      - name: chown
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          cp -LRv /mnt/ceph/*.keyring /etc/ceph/;
          cp -LRv /mnt/ceph-conf/ceph.conf /etc/ceph/ceph.conf;

          mkdir -p /var/lib/ceph/osd/ceph-${CEPH_NAME};

          chown -R 167:167 /etc/ceph;
          chown -R 167:167 /var/lib/ceph/osd/ceph-${CEPH_NAME};
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /mnt/ceph
          readOnly: true
        - name: ceph-conf
          mountPath: /mnt/ceph-conf
          readOnly: true
        - name: conf
          mountPath: /etc/ceph
        - name: data
          mountPath: /var/lib/ceph
      - name: setup
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          while ! ceph mon dump; do
            echo "Waiting for mon to be ready ...";
            sleep 5;
          done

          if [ ! -f /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid ]; then
            ceph-volume lvm prepare --data ${CEPH_LVM_VG}/${CEPH_LVM_LG} --dmcrypt --osd-id ${CEPH_NAME} --no-systemd;
            sleep 5;
            echo $(ceph-volume lvm list --format json | jq -r --arg osd "${CEPH_NAME}" 'getpath([$osd,0,"tags","ceph.osd_fsid"])') > /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid;
          fi
        env:
        - name: CEPH_LVM_LG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['ceph.kubernetes.progamesigner.dev/osd-lvm-lg']
        - name: CEPH_LVM_VG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['ceph.kubernetes.progamesigner.dev/osd-lvm-vg']
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
        securityContext:
          privileged: true
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
        - name: dev
          mountPath: /dev
        - name: run-ceph
          mountPath: /run/ceph
        - name: run-lvm
          mountPath: /run/lvm
        - name: run-udev
          mountPath: /run/udev
      containers:
      - name: osd
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          CEPH_FSID=$(cat /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid);

          ceph-volume lvm activate ${CEPH_NAME} ${CEPH_FSID} --no-systemd;

          exec ceph-osd --foreground --id=${CEPH_NAME} --setgroup=ceph --setuser=ceph;
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          limits:
            cpu: 300m
            memory: 16Gi
          requests:
            cpu: 100m
            memory: 2Gi
        securityContext:
          privileged: true
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
        - name: dev
          mountPath: /dev
        - name: run-lvm
          mountPath: /run/lvm
      priorityClassName: system-cluster-critical
      serviceAccountName: ceph
      volumes:
      - name: ceph
        hostPath:
          path: /etc/ceph
      - name: ceph-conf
        configMap:
          name: ceph
          items:
          - key: ceph.conf
            path: ceph.conf
      - name: conf
        emptyDir: {}
      - name: data
        hostPath:
          path: /var/lib/ceph
      - name: dev
        hostPath:
          path: /dev
      - name: run-ceph
        emptyDir: {}
      - name: run-lvm
        hostPath:
          path: /run/lvm
      - name: run-udev
        hostPath:
          path: /run/udev
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: osd
    app.kubernetes.io/name: ceph
    app.kubernetes.io/part-of: kubernetes
  name: ceph-osd-27a
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: osd
      app.kubernetes.io/name: ceph
      app.kubernetes.io/part-of: kubernetes
  template:
    metadata:
      annotations:
        ceph.kubernetes.progamesigner.dev/osd-lvm-lg: ceph-osd27a-lv
        ceph.kubernetes.progamesigner.dev/osd-lvm-vg: ceph-vg
      labels:
        app.kubernetes.io/component: osd
        app.kubernetes.io/name: ceph
        app.kubernetes.io/part-of: kubernetes
        ceph.kubernetes.progamesigner.dev/osd: '29'
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: osd.ceph.kubernetes.progamesigner.dev/27a
                operator: Exists
      automountServiceAccountToken: true
      hostIPC: true
      initContainers:
      - name: chown
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          cp -LRv /mnt/ceph/*.keyring /etc/ceph/;
          cp -LRv /mnt/ceph-conf/ceph.conf /etc/ceph/ceph.conf;

          mkdir -p /var/lib/ceph/osd/ceph-${CEPH_NAME};

          chown -R 167:167 /etc/ceph;
          chown -R 167:167 /var/lib/ceph/osd/ceph-${CEPH_NAME};
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          requests:
            cpu: 1m
            memory: 1Mi
        volumeMounts:
        - name: ceph
          mountPath: /mnt/ceph
          readOnly: true
        - name: ceph-conf
          mountPath: /mnt/ceph-conf
          readOnly: true
        - name: conf
          mountPath: /etc/ceph
        - name: data
          mountPath: /var/lib/ceph
      - name: setup
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          while ! ceph mon dump; do
            echo "Waiting for mon to be ready ...";
            sleep 5;
          done

          if [ ! -f /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid ]; then
            ceph-volume lvm prepare --data ${CEPH_LVM_VG}/${CEPH_LVM_LG} --dmcrypt --osd-id ${CEPH_NAME} --no-systemd;
            sleep 5;
            echo $(ceph-volume lvm list --format json | jq -r --arg osd "${CEPH_NAME}" 'getpath([$osd,0,"tags","ceph.osd_fsid"])') > /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid;
          fi
        env:
        - name: CEPH_LVM_LG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['ceph.kubernetes.progamesigner.dev/osd-lvm-lg']
        - name: CEPH_LVM_VG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['ceph.kubernetes.progamesigner.dev/osd-lvm-vg']
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
        securityContext:
          privileged: true
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
        - name: dev
          mountPath: /dev
        - name: run-ceph
          mountPath: /run/ceph
        - name: run-lvm
          mountPath: /run/lvm
        - name: run-udev
          mountPath: /run/udev
      containers:
      - name: osd
        image: ceph/ceph:latest
        command:
        - sh
        - -c
        - |
          set -ex;

          CEPH_FSID=$(cat /var/lib/ceph/osd/ceph-${CEPH_NAME}/fsid);

          ceph-volume lvm activate ${CEPH_NAME} ${CEPH_FSID} --no-systemd;

          exec ceph-osd --foreground --id=${CEPH_NAME} --setgroup=ceph --setuser=ceph;
        env:
        - name: CEPH_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['ceph.kubernetes.progamesigner.dev/osd']
        resources:
          limits:
            cpu: 300m
            memory: 8Gi
          requests:
            cpu: 100m
            memory: 2Gi
        securityContext:
          privileged: true
        volumeMounts:
        - name: conf
          mountPath: /etc/ceph
          readOnly: true
        - name: data
          mountPath: /var/lib/ceph
        - name: dev
          mountPath: /dev
        - name: run-lvm
          mountPath: /run/lvm
      priorityClassName: system-cluster-critical
      serviceAccountName: ceph
      volumes:
      - name: ceph
        hostPath:
          path: /etc/ceph
      - name: ceph-conf
        configMap:
          name: ceph
          items:
          - key: ceph.conf
            path: ceph.conf
      - name: conf
        emptyDir: {}
      - name: data
        hostPath:
          path: /var/lib/ceph
      - name: dev
        hostPath:
          path: /dev
      - name: run-ceph
        emptyDir: {}
      - name: run-lvm
        hostPath:
          path: /run/lvm
      - name: run-udev
        hostPath:
          path: /run/udev
